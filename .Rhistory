if (X$signal.type[y] != "ambient")
noise_clp <- seewave::ffilter(noise_clp, f = noise_clp@samp.rate, from = bp[1] * 1000, ovlp = ovlp,
to = bp[2] * 1000, bandpass = TRUE, wl = wl,
output = "Wave")
}
# get mean envelopes
sig_env <- mean(seewave::env(clp, f = clp@samp.rate, envt = "hil", plot = FALSE))
return(data.frame((X[y, , drop = FALSE]), sig_env))
}
meanenv_FUN <- function(y, wl, ovlp){
# read signal clip
clp <- warbleR::read_wave(X = X, index = y, from = 0, to = X$end[y])
if (X$signal.type[y] != "ambient")
noise_clp <- warbleR::read_wave(X = X, index = y, from = 0, to = X$start[y]- 0.001)
# add band-pass frequency filter
if (!is.null(bp)) {
# filter to bottom and top freq range
if (bp == "freq.range")
bp <- c(X$bottom.freq[y], X$top.freq[y])
clp <- seewave::ffilter(clp, f = clp@samp.rate, from = bp[1] * 1000, ovlp = ovlp,
to = bp[2] * 1000, bandpass = TRUE, wl = wl,
output = "Wave")
if (X$signal.type[y] != "ambient")
noise_clp <- seewave::ffilter(noise_clp, f = noise_clp@samp.rate, from = bp[1] * 1000, ovlp = ovlp,
to = bp[2] * 1000, bandpass = TRUE, wl = wl,
output = "Wave")
}
# get mean envelopes
sig_env <- mean(seewave::env(clp, f = clp@samp.rate, envt = "hil", plot = FALSE))
return(data.frame((X[y, , drop = FALSE]), sig_env))
}
# set clusters for windows OS
if (Sys.info()[1] == "Windows" & parallel > 1)
cl <- parallel::makePSOCKcluster(getOption("cl.cores", parallel)) else cl <- parallel
if (pb)
write(file = "", x = paste0("Calculating amplitude envelopes (step 2 out of 3):"))
# run loop apply function
SPLs <- warbleR:::pblapply_wrblr_int(X = 1:nrow(X), pbar = pb, cl = cl, FUN = function(y)  meanenv_FUN(y, wl, ovlp))
# put in a data frame
X2 <- do.call(rbind, SPLs)
# split by signal ID
sigtype_list <- split(X2, X2$signal.type)
sigtype_list
X2$signal.type
X
X$signal.type
table(X$signal.type)
sigtype_list[[1]]
names(sigtype_list)
sigtype_list[["0.2_BB_am_no.harm.wav_1"]]
Y <- sigtype_list[["0.2_BB_am_no.harm.wav_1"]]
# extract mean envelope of signals
sig_env_REF <- Y$sig_env[which.min(Y$distance)]
dist_REF <- Y$distance[which.min(Y$distance)]
ks <- Y$sig_env / sig_env_REF
ks
Y$sound.files
sig_env_REF
dist_REF
ks <- Y$sig_env / sig_env_REF
ea <-  (-20 * log(ks)) - (6 / (2 * (Y$distance - dist_REF))) + gain
ea <- gain -20 * log10(Y$distance / 10) -20 * log(ks)
Y$excess.attenuation <- ea
Y$excess.attenuation[which.min(Y$distance)] <- NA
Y
Y[,  c("excess.attenuation", "distance", "sound.files")]
Y[,  c("excess.attenuation", "distance", "sound.files", "sig_env")]
sig_env_REF
ks
Y$k <- ks
Y[,  c("excess.attenuation", "distance", "sound.files", "sig_env", "k")]
ks <- Y$sig_env / sig_env_REF
ea <-  (-20 * log(ks)) - (6 / (2 * (Y$distance - dist_REF))) + gain
Y$excess.attenuation <- ea
Y$excess.attenuation[which.min(Y$distance)] <- NA
Y[,  c("excess.attenuation", "distance", "sound.files", "sig_env", "k")]
# extract mean envelope of signals
sig_env_REF <- Y$sig_env[which.min(Y$distance)]
dist_REF <- Y$distance[which.min(Y$distance)]
ks <- Y$sig_env / sig_env_REF
ea <-  (-20 * log(ks)) - (6 / (2 * (Y$distance - dist_REF))) + gain
Y$excess.attenuation <- ea
Y$excess.attenuation[which.min(Y$distance)] <- NA
Y[,  c("excess.attenuation", "distance", "sound.files", "sig_env", "k")]
Y <- sigtype_list[["0.2_BB_am_no.harm.wav_1"]]
# extract mean envelope of signals
sig_env_REF <- Y$sig_env[which.min(Y$distance)]
dist_REF <- Y$distance[which.min(Y$distance)]
ks <- Y$sig_env / sig_env_REF
ea <-  (-20 * log(ks)) - (6 / (2 * (Y$distance - dist_REF))) + gain
Y$excess.attenuation <- ea
Y$excess.attenuation[which.min(Y$distance)] <- NA
Y[,  c("excess.attenuation", "distance", "sound.files", "sig_env", "k")]
Y[,  c("excess.attenuation", "distance", "sound.files", "sig_env")]
library(warbleR)
library(Rraven)
rav <- imp_raven(path = "~/Dropbox/File requests/owl sound files/", warbler.format = TRUE)
head(rav)
library(warbleR)
# read extended selection table with re-recorded signals
est.alg.sim.all <- readRDS("~/Dropbox/Projects/degradation_simulation/extended_sel_tab_tests_simulated_tests_sounds.RDS")
# all from transect 1 or 1 m distance
est.alg.sim.all <- est.alg.sim.all[est.alg.sim.all$Transecto == 1 | est.alg.sim.all$`Distancia (m)` == 1, ]
# all from closed habitata
est.alg.sim.all <- est.alg.sim.all[est.alg.sim.all$Vegetacion == "cerrado" | est.alg.sim.all$`Distancia (m)` == 1,]
# add column with original sound file name
est.alg.sim.all$org.sf <- sapply(strsplit(as.character(est.alg.sim.all$sound.files), ".wav",fixed=T), "[[", 1)
# should show count of signals per file names by distance
table(est.alg.sim.all$org.sf, est.alg.sim.all$`Distancia (m)`)
#this are the sound files to analized
unique(est.alg.sim.all$org.sf)
# get subset of signals to analyze
sub_est <- est.alg.sim.all[est.alg.sim.all$orig.sound.file %in% est.alg.sim.all$orig.sound.file[1:20], ]
# should be 100
nrow(sub_est)
# new name for output waves
sub_est$new.file.name <-  paste0("dist.", sub_est$`Distancia (m)`)
sub_est$new.selec <- sapply(strsplit(as.character(sub_est$sound.files), ".wav_",fixed=T), "[[", 2)
# rename
sub_est <- rename_est_waves(X = sub_est, new.sound.files = paste(sub_est$new.file.name,  sub_est$new.selec, sep = "-"), new.selec = 1)
which(sub_est$`Distancia (m)` != 1)
x = 21
wv <- read_sound_file(X = sub_est, x)
wv <- normalize(wv, unit = "16", rescale = FALSE)
ns <- read_sound_file(X = sub_est, x, from = 0, to = 0.03)
ns <- normalize(ns, unit = "16", rescale = FALSE)
for(i in 1:6)
est.alg.sim.all
est.alg.sim.all
wv <- read_sound_file(X = sub_est, x)
wv
wv <- read_sound_file(X = sub_est, x, to = 1000)
wv
wv
wv <- read_sound_file(X = sub_est, x to =100000)
wv <- read_sound_file(X = sub_est, x,  to =100000)
wv
wv <- read_sound_file(X = sub_est, x,  to = 100000)
wv <- read_sound_file(X = sub_est, x,  to = 100000)
wv <- read_sound_file(X = sub_est, x,  to = 1000)
wv
wv <- read_sound_file(X = sub_est, x,  to = sub_est$end[x] + 0.04)
wv
out <- sapply(which(sub_est$`Distancia (m)` != 1), function(x){
wv <- read_sound_file(X = sub_est, x,  to = sub_est$end[x] + 0.04)
wv <- normalize(wv, unit = "16", rescale = FALSE)
ns <- read_sound_file(X = sub_est, x, from = 0, to = 0.03)
ns <- normalize(ns, unit = "16", rescale = FALSE)
for(i in 1:6)
ns <- pastew(wave1 = ns, wave2 = ns, output = "Wave")
wv <- pastew(cutw(ns, from = 0, to =  1, output = "Wave"), wv, output = "Wave")
writeWave(wv, file.path("./data/raw/precise_cuts2/", paste0(sub_est$sound.files[x], ".wav")), extensible = FALSE)
})
# export 1 m controls removing margins
out <- sapply(which(sub_est$`Distancia (m)` == 1), function(x){
wv <- read_sound_file(X = sub_est, x)
wv <- normalize(wv, unit = "16", rescale = FALSE)
writeWave(wv, file.path("/home/neuro/Dropbox/estudiantes/Marcos Quiroz/sigpro_measuring/controls/", paste0(sub_est$sound.files[x], ".wav")), extensible = FALSE)
})
path <- dest.path <- "/media/m/Seagate Portable Drive/rafII_videos/Hembras videos crudos"
file.ext = c".MP4$|.mp4$"
files = NULL
pb = TRUE
parallel = 1
save.csv = TRUE
#### set arguments from options
# get function arguments
argms <- methods::formalArgs(consolidate)
# get warbleR options
opt.argms <- if(!is.null(getOption("warbleR"))) getOption("warbleR") else SILLYNAME <- 0
# remove options not as default in call and not in function arguments
opt.argms <- opt.argms[!sapply(opt.argms, is.null) & names(opt.argms) %in% argms]
# get arguments set in the call
call.argms <- as.list(base::match.call())[-1]
# remove arguments in options that are in call
opt.argms <- opt.argms[!names(opt.argms) %in% names(call.argms)]
# set options left
if (length(opt.argms) > 0)
for (q in 1:length(opt.argms))
assign(names(opt.argms)[q], opt.argms[[q]])
# check path to working directory
if (is.null(path)) path <- getwd() else
if (!dir.exists(path))
stop2("'path' provided does not exist") else
path <- normalizePath(path)
# check path to working directory
if (!is.null(dest.path))
{
if (!dir.exists(dest.path)) stop2("'dest.path' provided does not exist") else
dest.path <- normalizePath(dest.path)
} else
dir.create(dest.path <- file.path(path, "consolidated_files"), showWarnings = FALSE)
# list files
if (!is.null(files)){
fe <- file.exists(as.character(files))
# stop if files are not in working directory
if (length(fe) == 0) stop2("files were not found")
if (length(fe) < length(files)) cat("some files were not found")
files <- files[fe]
} else
files <- list.files(path = path, pattern = file.ext, ignore.case = TRUE, recursive = TRUE, full.names = TRUE)
file.ext = ".MP4$|.mp4$"
# list files
if (!is.null(files)){
fe <- file.exists(as.character(files))
# stop if files are not in working directory
if (length(fe) == 0) stop2("files were not found")
if (length(fe) < length(files)) cat("some files were not found")
files <- files[fe]
} else
files <- list.files(path = path, pattern = file.ext, ignore.case = TRUE, recursive = TRUE, full.names = TRUE)
# stop if files are not in working directory
if (length(files) == 0) stop2("no files found in working directory and/or subdirectories")
# create new names for duplicated songs
old_name <- basename(files)
files <- files[order(old_name)]
old_name <- old_name[order(old_name)]
file_size_bytes <- file.size(files)
# rename if any duplicated names
new_name <- unlist(lapply(unique(old_name),
function(x) {
on <- old_name[old_name == x]
if (length(on) > 1) return(paste0(gsub(file.ext, "", on, ignore.case = TRUE), "-", seq_len(length(on)), gsub("$","", file.ext, fixed = TRUE))) else return(x)}))
new_name <- gsub("\\", "", new_name, fixed = TRUE)
# create data frame with info from old and new names
X <- data.frame(original_dir = gsub("\\.", path, dirname(files), fixed = TRUE), old_name, new_name, file_size_bytes, stringsAsFactors = FALSE)
# label possible duplicates
X$duplicate <- sapply(paste0(X$old_name, X$file_size_bytes), function(y) if (length(which(paste0(X$old_name, X$file_size_bytes) == y)) > 1) return("possible.dupl") else return(NA))
# If parallel is not numeric
if (!is.numeric(parallel)) stop2("'parallel' must be a numeric vector of length 1")
if (any(!(parallel %% 1 == 0),parallel < 1)) stop2("'parallel' should be a positive integer")
df$original_dir
df
df <- X
df$original_dir
dp
dest.path
source("~/Dropbox/R_package_testing/warbleR/R/consolidate.R")
cns <- consolidate(file.ext = c"\\.MP4$|\\.mp4$", path = "/media/m/Seagate Portable Drive/rafII_videos", dest.path = "/media/m/Seagate Portable Drive/rafII_videos/consolidated_files", parallel = 4)
source("~/Dropbox/R_package_testing/warbleR/R/consolidate.R")
cns <- consolidate(file.ext = "\\.MP4$|\\.mp4$", path = "/media/m/Seagate Portable Drive/rafII_videos", dest.path = "/media/m/Seagate Portable Drive/rafII_videos/consolidated_files", parallel = 4)
source("~/Dropbox/R_package_testing/warbleR/R/internal_functions.R")
cns <- consolidate(file.ext = "\\.MP4$|\\.mp4$", path = "/media/m/Seagate Portable Drive/rafII_videos", dest.path = "/media/m/Seagate Portable Drive/rafII_videos/consolidated_files", parallel = 4)
library(warbleR)
library(seewave)
library(tuneR)
library(baRulho)
library(Rraven)
vignette("Rraven")
getwd()
rvn.dat <- imp_raven(all.data = TRUE, path = "C:\Users\Marcos\Dropbox\Marcos Quiroz\barulho_paper\data\raw\consolidated.master.sf_selection_table")
source("~/Dropbox/R_package_testing/ohun/R/optimize_energy_detector.R")
60 * 3
60 * 3 + 39
60 * 14 + 21
60 * 14 + 0
# github packages must include user name ("user/package")
# knitr is require for creating html/pdf/word reports
# kableExtra is used to print pretty formatted tables
# formatR is used for soft-wrapping code
# klippy is used for adding a copy button to each code block
pkgs <- c("rlesur/klippy", "kableExtra", "knitr", "formatR", "rprojroot", "readxl", "ggplot2", "viridis", "corrplot", "maRce10/baRulho", "irr")
# install/ load packages
out <- lapply(pkgs, function(y) {
# get pakage name
pkg <- strsplit(y, "/")[[1]]
pkg <- pkg[length(pkg)]
# check if installed, if not then install
if (!pkg %in% installed.packages()[,"Package"])  {
if (grepl("/", y))  remotes::install_github(y, force = TRUE) else
install.packages(y)
}
# load package
a <- try(require(pkg, character.only = T), silent = T)
if (!a) remove.packages(pkg)
})
# set working directory as project directory or one directory above,
rootdir <- try(rprojroot::find_rstudio_root_file(), silent = TRUE)
if (is(rootdir, "try-error")) rootdir <-  ".."
opts_knit$set(root.dir = rootdir)
# options to customize chunk outputs
knitr::opts_chunk$set(
class.source = "numberLines lineAnchors", # for code line numbers
tidy.opts = list(width.cutoff = 65),
tidy = TRUE,
message = FALSE,
warning = FALSE
)
# this is a customized printing style data frames
# screws up tibble function
tibble <- function(x, ...) {
x <- kbl(x, digits=4, align= 'c', row.names = FALSE)
x <- kable_styling(x, position ="center", full_width = FALSE,  bootstrap_options = c("striped", "hover", "condensed", "responsive"))
asis_output(x)
}
registerS3method("knit_print", "data.frame", tibble)
# to add copy button to code blocks
klippy::klippy(position = c('top', 'right'))
theme_set(theme_classic(base_size = 20))
cap_fun <- function(x) {
s <- strsplit(x, " ")[[1]]
paste(toupper(substring(s, 1, 1)), substring(s, 2),
sep = "", collapse = " ")
}
# Chunk 1: load packages and setup style
# github packages must include user name ("user/package")
# knitr is require for creating html/pdf/word reports
# kableExtra is used to print pretty formatted tables
# formatR is used for soft-wrapping code
# klippy is used for adding a copy button to each code block
pkgs <- c("remotes", "kableExtra", "knitr", "formatR", "rprojroot", "maRce10/warbleR", "ggplot2", "tidyr", "viridis", "corrplot", "brms", "ggdist", "cowplot", "cmdstanr", "maRce10/brmsish")
# install/ load packages
out <- lapply(pkgs, function(y) {
# get pakage name
pkg <- strsplit(y, "/")[[1]]
pkg <- pkg[length(pkg)]
# check if installed, if not then install
if (!pkg %in% installed.packages()[,"Package"])  {
if (grepl("/", y))  remotes::install_github(y, force = TRUE) else
install.packages(y)
}
# load package
a <- try(require(pkg, character.only = T), silent = T)
if (!a) remove.packages(pkg)
})
# set working directory as project directory or one directory above,
rootdir <- try(rprojroot::find_rstudio_root_file(), silent = TRUE)
if (is(rootdir, "try-error")) rootdir <-  ".."
opts_knit$set(root.dir = rootdir)
# options to customize chunk outputs
knitr::opts_chunk$set(
class.source = "numberLines lineAnchors", # for code line numbers
tidy.opts = list(width.cutoff = 65),
tidy = TRUE,
message = FALSE
)
# this is a customized printing style data frames
# screws up tibble function
tibble <- function(x, ...) {
x <- kbl(x, digits=4, align= 'c', row.names = FALSE)
x <- kable_styling(x, position ="center", full_width = FALSE,  bootstrap_options = c("striped", "hover", "condensed", "responsive"))
asis_output(x)
}
registerS3method("knit_print", "data.frame", tibble)
# to add copy button to code blocks
htmltools::tagList(
xaringanExtra::use_clipboard(
button_text = "<i class=\"fa fa-clipboard\"></i>",
success_text = "<i class=\"fa fa-check\" style=\"color: #90BE6D\"></i>",
error_text = "<i class=\"fa fa-times-circle\" style=\"color: #F94144\"></i>"
),
rmarkdown::html_dependency_font_awesome()
)
theme_set(theme_classic(base_size = 17))
# Chunk 2: read data degradation
degrad_df <- read.csv("./data/processed/barulho_degradation_metrics.csv", stringsAsFactors = FALSE)
degrad_params <- c(bl.rt = "blur.ratio", sp.bl.rt = "spectral.blur.ratio", env.cr = "envelope.correlation", EA ="excess.attenuation", SPL = "SPL", SNR = "signal.to.noise.ratio", SPCC = "cross.correlation",  TSR = "tail.to.signal.ratio", TNR = "tail.to.noise.ratio", sp.cr = "spectrum.correlation", pc1 = "pc1")
master_metadata <- read.csv("./data/raw/consolidated.master.sf_selection_table.csv")
# keep only simulated data (exluding data from a student)
master_metadata <- master_metadata[2:961, ]
# infer original frequency
possb_freqs <- seq(0.5, 10, length.out = 20)
master_metadata$freq <- sapply(1:nrow(master_metadata), function(x)
possb_freqs[which.min(abs((master_metadata$top.freq[x] + master_metadata$bottom.freq[x]) / 2 - possb_freqs))]
)
freq_contour <- freq_ts(master_metadata, length.out = 20, parallel = 22, img = FALSE, path = "./data/raw/master_sound_file", pb = FALSE)
freq_contour$mean.freq <- rowMeans(freq_contour[, 3:ncol(freq_contour)])
freq_contour$orig_sound_file <- master_metadata$orig.sound.file
degrad_df$frequency <- sapply(1:nrow(degrad_df), function(x)
freq_contour$mean.freq[freq_contour$orig_sound_file == degrad_df$sound.id[x]]
)
degrad_df$sim.frequency <- sapply(1:nrow(degrad_df), function(x)
master_metadata$freq[master_metadata$orig.sound.file == degrad_df$sound.id[x]]
)
degrad_df <- separate(degrad_df, col = sound.id, into = c("Duration", "Freq_modulation", "Amp_modulation", "Harmonicity", "delete"), remove = FALSE, sep = "_")
degrad_df$Duration <- ifelse(degrad_df$Duration == 0.1, "short", "long")
degrad_df$`Freq_modulation` <- ifelse(degrad_df$`Freq_modulation` == "BB", "fm", "no_fm")
degrad_df$Harmonicity <- gsub(".wav", "", degrad_df$Harmonicity)
degrad_df$delete <- NULL
degrad_df$treatment.replicates <- paste0("frq:", "_", degrad_df$sim.frequency, "dur:", degrad_df$Duration, "_", degrad_df$Amp_modulation, "_", degrad_df$Freq_modulation)
degrad_df$Freq_modulation <- factor(degrad_df$Freq_modulation, levels = c("no_fm", "fm"))
degrad_df$Amp_modulation[degrad_df$Amp_modulation == "no.am"] <- "no_am"
degrad_df$Amp_modulation <- factor(degrad_df$Amp_modulation, levels = c("no_am", "am"))
degrad_df$duration <- factor(degrad_df$Duration, levels = c("short", "long"))
degrad_df <- degrad_df[degrad_df$Harmonicity != "harm", ]
degrad_df <- degrad_df[degrad_df$distance > 1, ]
degrad_df$frequency <- degrad_df$sim.frequency
degrad_df$duration <- degrad_df$Duration
degrad_df$amplitude.modulation <- degrad_df$Amp_modulation
degrad_df$frequency.modulation <- degrad_df$Freq_modulation
degrad_df$location <- degrad_df$Transect
degrad_df$spectrum.blur.ratio <- degrad_df$spectral.blur.ratio
degrad_df$habitat.structure <- ifelse(degrad_df$Vegetacion == "abierta", "open", "closed")
degrad_df$sim.frequency <- degrad_df$signal.to.noise.ratio.t2 <- degrad_df$SPL <- degrad_df$template <- degrad_df$data.set <- degrad_df$Temperatura <- degrad_df$Harmonicity <- degrad_df$freq <- degrad_df$Humedad <- degrad_df$Vegetacion <- degrad_df$Duration <- degrad_df$orig.sound.file <- degrad_df$Freq_modulation <- degrad_df$Amp_modulation <- degrad_df$spectral.blur.ratio <- degrad_df$Transecto <- NULL
names(degrad_df)
degrad_df <- degrad_df[, c("sound.files", "selec", "start", "end", "bottom.freq", "top.freq", "sound.id",  "habitat.structure", "distance", "reference", "frequency", "duration", "treatment.replicates", "location", "frequency.modulation", "amplitude.modulation","blur.ratio", "envelope.correlation", "excess.attenuation", "signal.to.noise.ratio", "cross.correlation", "spectrum.blur.ratio", "spectrum.correlation", "tail.to.noise.ratio", "tail.to.signal.ratio")]
write.csv(degrad_df, "./data/processed/tlalpan_degradation_metrics_v01.csv", row.names = FALSE)
# Chunk 3: add PCA
degrad_df <- read.csv("./data/processed/tlalpan_degradation_metrics_v01.csv")
degrad_params <- c("blur.ratio", "spectrum.blur.ratio", "envelope.correlation", "excess.attenuation", "signal.to.noise.ratio", "cross.correlation", "tail.to.signal.ratio", "tail.to.noise.ratio", "spectrum.correlation")
comp.cases <- complete.cases(degrad_df[,names(degrad_df) %in% degrad_params])
pca <- prcomp(degrad_df[comp.cases, names(degrad_df) %in% degrad_params], scale. = TRUE)
# add to data
degrad_df$pc1 <- NA
degrad_df$pc1[comp.cases] <- pca$x[, 1]
degrad_df$pc1.1m.rate <- degrad_df$distance
# plot rotation values by PC
pca_rot <- as.data.frame(pca$rotation[, 1:4])
pca_rot_stck <- stack(pca_rot)
pca_rot_stck$variable <- rownames(pca_rot)
pca_rot_stck$Sign <- ifelse(pca_rot_stck$values > 0, "Positive", "Negative")
pca_rot_stck$rotation <- abs(pca_rot_stck$values)
ggplot(pca_rot_stck, aes(x = variable, y = rotation, fill = Sign)) +
geom_col() +
coord_flip() +
scale_fill_viridis_d(alpha = 0.7, begin = 0.3, end = 0.8) +
facet_wrap(~ ind)
# Chunk 4: correlation among raw metrics
cormat <- cor(degrad_df[, degrad_params], use = "pairwise.complete.obs")
rownames(cormat) <- colnames(cormat) <- degrad_params
cols_corr <- colorRampPalette(c("white", "white", viridis(4, direction = -1)))(10)
cp <- corrplot.mixed(cormat, tl.cex = 0.7,
upper.col = cols_corr,
lower.col = cols_corr,
order = "hclust",
lower = "number",
upper = "ellipse",
tl.col = "black")
# sort parameters as in clusters for cross correlation
degrad_params <- degrad_params[match(rownames(cp$corr), degrad_params)]
# Chunk 5
agg <- aggregate(cbind(sound.id, treatment.replicates) ~ location + habitat.structure + distance, degrad_df, function(x) length(unique(x)))
agg$replicates <- agg$sound.id / agg$treatment.replicates
agg
names(degrad_df)
iter <- 10000
chains <- 4
priors <- c(prior(normal(0, 6), class = "b"), prior(cauchy(0, 4), class = "sd"))
# set frequency to mean-centered
degrad_df$frequency <- scale(degrad_df$frequency, scale = FALSE)
# set base level for factors
degrad_df$habitat.structure <- factor(degrad_df$habitat.structure, levels = c("open", "closed"))
degrad_df$frequency.modulation <- factor(degrad_df$frequency.modulation, levels = c("no_fm", "fm"))
degrad_df$amplitude.modulation <- factor(degrad_df$amplitude.modulation, levels = c("no_am", "am"))
degrad_df$duration <- factor(degrad_df$duration, levels = c("short", "long"))
degrad_df$location <- as.factor(degrad_df$location)
# degrad_df$ord.distance <- ordered(degrad_df$distance)
set.seed(123)
cmdstanr::set_cmdstan_path("~/Documentos/cmdstan/")
mod_blurratio <-
brm(
formula = blur.ratio ~  frequency * habitat.structure + frequency.modulation * habitat.structure + amplitude.modulation * habitat.structure  + duration * habitat.structure + mo(distance) + (1 | location) + (1 | treatment.replicates),
data = degrad_df,
prior = priors,
iter = iter,
chains = chains,
cores = chains,
control = list(adapt_delta = 0.99, max_treedepth = 15),
file = "./data/processed/regression_model_blur_ratio.RDS",
file_refit = "always",
backend = "cmdstanr",
threads = threading(10)
)
mod_excessattenuation <-
brm(
formula = excess.attenuation ~  frequency * habitat.structure + frequency.modulation * habitat.structure + amplitude.modulation * habitat.structure  + duration * habitat.structure + mo(distance) + (1 | location) + (1 | treatment.replicates),
data = degrad_df,
prior = priors,
iter = iter,
chains = chains,
cores = chains,
control = list(adapt_delta = 0.99, max_treedepth = 15),
file = "./data/processed/regression_model_excess_attenuation.RDS",
file_refit = "always",
backend = "cmdstanr",
threads = threading(10)
)
mod_signal.to.noise.ratio <-
brm(
formula = signal.to.noise.ratio ~  frequency * habitat.structure + frequency.modulation * habitat.structure + amplitude.modulation * habitat.structure  + duration * habitat.structure + mo(distance) + (1 | location) + (1 | treatment.replicates),
data = degrad_df,
prior = priors,
iter = iter,
chains = chains,
cores = chains,
control = list(adapt_delta = 0.99, max_treedepth = 15),
file = "./data/processed/regression_signal-to-noise_ratio.RDS",
file_refit = "always",
backend = "cmdstanr",
threads = threading(10)
)
mod_tail.to.signal.ratio <-
brm(
formula = tail.to.signal.ratio ~  frequency * habitat.structure + frequency.modulation * habitat.structure + amplitude.modulation * habitat.structure  + duration * habitat.structure + mo(distance) + (1 | location) + (1 | treatment.replicates),
data = degrad_df,
prior = priors,
iter = iter,
chains = chains,
cores = chains,
control = list(adapt_delta = 0.99, max_treedepth = 15),
file = "./data/processed/regression_model_tail-to-signal_ratio.RDS",
file_refit = "always",
backend = "cmdstanr",
threads = threading(10)
)
mod_tail.to.signal.ratio
brmsish::extended_summary(read.file = "./data/processed/regression_model_pc1.RDS", n.posterior = 1000, fill = "orange3", trace.palette = my.viridis,  remove.intercepts = TRUE, highlight = TRUE, gsub.pattern = c("b_", "habitat.structureclosed", "amplitude.modulationam", "frequency.modulationfm", "durationlong"), gsub.replacement = c("", "habitat structure", "amplitude modulation", "frequency modulation", "duration"))
my.viridis <- function(...) viridis(alpha = 0.5, begin = 0.3, end = 0.7, ...)
brmsish::extended_summary(read.file = "./data/processed/regression_model_pc1.RDS", n.posterior = 1000, fill = "orange3", trace.palette = my.viridis,  remove.intercepts = TRUE, highlight = TRUE, gsub.pattern = c("b_", "habitat.structureclosed", "amplitude.modulationam", "frequency.modulationfm", "durationlong"), gsub.replacement = c("", "habitat structure", "amplitude modulation", "frequency modulation", "duration"))
brmsish::extended_summary(read.file = "./data/processed/regression_model_pc1.RDS", n.posterior = 1000, fill = "orange3", trace.palette = my.viridis,  remove.intercepts = TRUE, highlight = TRUE, gsub.pattern = c("b_", "habitat.structureclosed", "amplitude.modulationam", "frequency.modulationfm", "durationlong"), gsub.replacement = c("", "habitat structure", "amplitude modulation", "frequency modulation", "duration"), c("b_habitat.structureclosed")
brmsish::extended_summary(read.file = "./data/processed/regression_model_pc1.RDS", n.posterior = 1000, fill = "orange3", trace.palette = my.viridis,  remove.intercepts = TRUE, highlight = TRUE, gsub.pattern = c("b_", "habitat.structureclosed", "amplitude.modulationam", "frequency.modulationfm", "durationlong"), gsub.replacement = c("", "habitat structure", "amplitude modulation", "frequency modulation", "duration"), effects = c("b_habitat.structureclosed"))
brmsish::extended_summary(read.file = "./data/processed/regression_model_pc1.RDS", n.posterior = 1000, fill = "orange3", trace.palette = my.viridis,  remove.intercepts = TRUE, highlight = TRUE, gsub.pattern = c("b_", "habitat.structureclosed", "amplitude.modulationam", "frequency.modulationfm", "durationlong"), gsub.replacement = c("", "habitat structure", "amplitude modulation", "frequency modulation", "duration"), effects = c("habitat.structure"))
